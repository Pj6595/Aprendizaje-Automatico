{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 3: Regresión logística multi-clase y redes neuronales {-}\n",
    "Álvar Domingo Fernández y Pablo Jurado López"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Preparación inicial {-}\n",
    "A continuación se importan todas las librerías externas que serán utilizadas en esta práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.lib.npyio import load\n",
    "import scipy.optimize as opt\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Regresión logística multi-clase {-}\n",
    "\n",
    "### 1.1 - Visualización de los datos {-}\n",
    "Se ha cargado, con la función loadmat de scipy.io, los ejemplos de entrenamiento de la práctica en forma de diccionario, del cual se han extraído las matrices X e y (para y hemos tenido que utilizar la función .ravel(), que la convierte en una matriz unidimensional).\n",
    "\n",
    "A continuación, haciendo uso de la librería matplot, se ha generado una imagen formada por 10 ejemplos de entrenamiento aleatorios, que en esta ocasión son números escritos a mano."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('ex3data1.mat')\n",
    "y = data['y'].ravel()\n",
    "X = data['X']\n",
    "\n",
    "sample = np.random.choice(X.shape[0], 10)\n",
    "plt.imshow(X[sample, :].reshape(-1, 20).T)\n",
    "plt.axis('off')\n",
    "plt.savefig('numeros.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Representación de los 10 ejemplos de entrenamiento aleatorios](numeros.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 - Clasificación de uno frente a todos {-}\n",
    "Se ha implementado una función oneVsAll que entrena un clasificador por regresión logística para todas las clases del conjunto de datos. Para ello, se hará uso de algunas funciones desarrolladas en la práctica anterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoide(target):\n",
    "    result = 1 / (1 + np.exp(-target))\n",
    "    return result\n",
    "\n",
    "\n",
    "def costeReg(thetas, x, y, lamb):\n",
    "    sigXT = sigmoide(np.matmul(x, thetas))\n",
    "    return (-1/np.shape(x)[0]) * (np.matmul(np.transpose(np.log(sigXT)), y) + np.matmul(np.transpose(np.log(1-sigXT)), (1-y))) + ((lamb/(2*np.shape(x)[0])) * sum(thetas ** 2))\n",
    "\n",
    "\n",
    "def gradienteReg(thetas, x, y, lamb):\n",
    "    sigXT = sigmoide(np.matmul(x, thetas))\n",
    "    return ((1/np.shape(x)[0]) * np.matmul(np.transpose(x), (sigXT - y))) + ((lamb/np.shape(x)[0]) * thetas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, en oneVsAll entrenaremos a los clasificadores para cada una de las 10 clases del ejemplo (con num_etiquetas = 10) haciendo uso de la función opt.fmin_tnc y las descritas anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneVsAll(X, y, num_etiquetas, reg):\n",
    "    clasificadores = np.zeros(shape=(10, 400))\n",
    "\n",
    "    for i in range(1, num_etiquetas + 1):\n",
    "        filtrados = (y == i) * 1\n",
    "        thetas = np.zeros(np.shape(X)[1])\n",
    "        clasificadores[i - 1] = opt.fmin_tnc(\n",
    "            func=costeReg, x0=thetas, fprime=gradienteReg, args=(X, filtrados, reg))[0]\n",
    "\n",
    "    return clasificadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el siguiente método se harán unas predicciones en base a los clasificadores que se han generado y se comparará cada una de ellas con el valor de y, obteniendo así el porcentaje de precisión del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion(X, Y, clasificadores):\n",
    "    predicciones = {}\n",
    "    Y_pred = []\n",
    "    for imagen in range(np.shape(X)[0]):\n",
    "        for i in range(clasificadores.shape[0]):\n",
    "            theta_opt = clasificadores[i]\n",
    "            etiqueta = i + 1\n",
    "            prediccion = sigmoide(\n",
    "                np.matmul(np.transpose(theta_opt), X[imagen]))\n",
    "\n",
    "            predicciones[etiqueta] = prediccion\n",
    "        Y_pred.append(max(predicciones.items(), key=operator.itemgetter(1))[0])\n",
    "    return np.sum((Y == np.array(Y_pred)))/np.shape(X)[0] * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la precisión resultante es de un 95,88%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Redes Neuronales {-}\n",
    "Hemos cargado el fichero ex3weights.mat, a partir del cual se han obtenido las matrices Theta1 y Theta2. A partir de ellas se ha implementado la función que ejecuta la propagación hacia delante de la red y devuelve el valor de $a_3$, o $h_0$, para cada uno de los ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = loadmat('ex3weights.mat')\n",
    "data = loadmat('ex3data1.mat')\n",
    "theta1, theta2 = weights['Theta1'], weights['Theta2']\n",
    "\n",
    "def propagar(X, theta1, theta2):\n",
    "    m = np.shape(X)[0]\n",
    "\n",
    "    a1 = np.hstack([np.ones([m, 1]), X])\n",
    "    z2 = np.dot(a1, theta1.T)\n",
    "    a2 = np.hstack([np.ones([m, 1]), sigmoide(z2)])\n",
    "    z3 = np.dot(a2, theta2.T)\n",
    "    a3 = sigmoide(z3)\n",
    "    return a3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para obtener la precisión de los resultados de la red neuronal, también se ha implementado una función que genera predicciones en base al resultado de la propagación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediccion_neuronal(X, a3):\n",
    "    return [(np.argmax(a3[imagen]) + 1) for imagen in range(X.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y finalmente, siguiendo el mismo procedimiento que en el apartado 1, se ha obtenido el porcentaje de aciertos del modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = propagar(X, theta1, theta2)\n",
    "Y_pred = prediccion_neuronal(X, h)\n",
    "precision = np.sum((y == np.array(Y_pred))) / np.shape(X)[0]\n",
    "print(\"La precisión de la red neuronal es de \", precision * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, la precisión de los resultados ha sido de un 97,52%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
