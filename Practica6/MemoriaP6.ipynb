{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 6 - Support Vector Machines {-}\n",
    "Álvar Domingo Fernández y Pablo Jurado López"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparación inicial {-}\n",
    "A continuación se importan todas las librerías y funciones externas que serán utilizadas en esta práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.svm import SVC\n",
    "from process_email import email2TokenList\n",
    "import codecs\n",
    "from get_vocab_dict import getVocabDict\n",
    "import glob\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1- Kernel lineal {-}\n",
    "Hemos clasificado los datos contenidos en ex6data1.mat con un SVM con un parámetro de regularización C=1 y una función de kernel lineal, y lo hemos renderizado en una gráfica. Posteriormente hemos repetido el mismo proceso, esta vez con un parámetro de regularización C = 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apartado1_1():\n",
    "    data = loadmat('ex6data1.mat')\n",
    "    X, y = data['X'], data['y'].ravel() \n",
    "    svm = SVC(kernel= 'linear', C = 1)\n",
    "    visualize_boundary(X, y, svm, \"apartado1_1_C1\")\n",
    "    svm = SVC(kernel= 'linear', C = 100)\n",
    "    visualize_boundary(X, y, svm, \"apartado1_1_C100\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SVM lineal con C = 1](apartado1_1_C1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SVM lineal con C = 100](apartado1_1_C100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2- Kernel gaussiano {-}\n",
    "Hemos repetido el proceso del apartado anterior, pero esta vez hemos utilizado una función de kernel gaussiana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apartado1_2():\n",
    "    data = loadmat('ex6data2.mat')\n",
    "    X, y = data['X'], data['y'].ravel() \n",
    "    C = 1\n",
    "    sigma = 0.1 \n",
    "    svm = SVC(kernel= 'rbf', C = C, gamma=1 / (2 * sigma**2))\n",
    "    visualize_boundary(X, y, svm, \"apartado1_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![SVM con kernel gaussiano](apartado1_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3- Elección de los parámetros C y $\\sigma$ {-}\n",
    "Hemos utilizado la función svm.score y probado con los siguientes valores para C y $\\sigma$: [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apartado1_3():\n",
    "    data = loadmat('ex6data3.mat')\n",
    "    X = data['X']\n",
    "    y = data['y'].ravel()\n",
    "    Xval = data['Xval']\n",
    "    yval = data['yval'].ravel()\n",
    "    values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]\n",
    "    n = len(values)\n",
    "    scores = np.zeros((n, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        C = values[i]\n",
    "        for j in range(n):\n",
    "            sigma = values[j]\n",
    "            svm = SVC(kernel='rbf', C = C, gamma= 1 / (2 * sigma **2))\n",
    "            svm.fit(X, y.ravel())\n",
    "            scores[i, j] = svm.score(Xval, yval)\n",
    "\n",
    "    print(\"Error mínimo: {}\".format(1 - scores.max())) \n",
    "    C_opt = values[scores.argmax()//n]\n",
    "    sigma_opt = values[scores.argmax()%n]\n",
    "    print(\"C óptimo: {}, sigma óptimo: {}\".format(C_opt, sigma_opt))\n",
    "\n",
    "    svm = SVC(kernel= 'rbf', C = C_opt, gamma= 1 / (2 * sigma_opt ** 2))\n",
    "    visualize_boundary(X, y, svm, \"apartado1_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado obtenido es el siguiente:  \n",
    "Error mínimo: 0.03500000000000003  \n",
    "C óptimo: 1, $\\sigma$ óptimo: 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Detección de spam {-}\n",
    "Para leer los datos hemos utilizado una función llamada _read_directory_, escrita a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_directory(name, vocab):\n",
    "    files = glob.glob(name)\n",
    "    X = np.zeros((len(files), len(vocab)))\n",
    "    y = np.ones(len(files))\n",
    "    i = 0\n",
    "    for f in files:\n",
    "        email_contents = codecs.open(f, 'r', encoding='utf-8', errors='ignore').read()\n",
    "        tokens = email2TokenList(email_contents)\n",
    "        words = filter(None,[vocab.get(x) for x in tokens])\n",
    "        for w in words:\n",
    "            X[i, w-1] = 1\n",
    "        i +=1\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que hace es abrir todos los archivos de cierto directorio, cuenta las veces que sale cada palabra del vocabulario y devuelve una matriz \"X\" con estos datos y una matriz \"y\" de unos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def palabras_comunes(X, fracción):\n",
    "    num_palabras = int(np.round(len(X[0])*fracción))\n",
    "    frecuencia = np.sort(X.sum(0))[-num_palabras]\n",
    "    atributos = np.where(X.sum(0) >= frecuencia)[0]\n",
    "    return X[:, atributos]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función _palabras_comunes_ saca una submatriz de la original en la que solo están las palabras más comunes según la fracción del total que se indique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_emails(X, y):\n",
    "    X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = ms.train_test_split(X_train, y_train, test_size=0.25, random_state=1) \n",
    "\n",
    "    values = [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300]\n",
    "    n = len(values)\n",
    "    scores = np.zeros((n, n))\n",
    "\n",
    "    startTime = time.process_time()\n",
    "\n",
    "    for i in range(n):\n",
    "        C = values[i]\n",
    "        for j in range(n):\n",
    "            sigma = values[j]\n",
    "            svm = SVC(kernel='rbf', C = C, gamma= 1 / (2 * sigma **2))\n",
    "            svm.fit(X_train, y_train)\n",
    "            scores[i, j] = svm.score(X_val, y_val)\n",
    "\n",
    "    print(\"Error mínimo: {}\".format(1 - scores.max())) \n",
    "    C_opt = values[scores.argmax()//n]\n",
    "    sigma_opt = values[scores.argmax()%n]\n",
    "    print(\"C óptimo: {}, sigma óptimo: {}\".format(C_opt, sigma_opt))\n",
    "\n",
    "    svm = SVC(kernel='rbf', C= C_opt, gamma=1 / (2 * sigma_opt)**2)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    endTime = time.process_time()\n",
    "\n",
    "    score = svm.score(X_test, y_test)\n",
    "    totalTime = endTime - startTime\n",
    "   \n",
    "    print('Precisión: {:.3f}%'.format(score*100))\n",
    "    print('Tiempo de ejecución: {}'.format(totalTime))\n",
    "    print('Matriz de confusión: ')\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_score_emails_ utiliza SVC para clasificar los emails e intenta buscar el C y $\\sigma$ óptimos de entre estos valores: [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300]. También se guarda el tiempo guardado, la precisión y la matriz de confusión. A continuación veremos la diferencia de resultados entre hacer reducción de atributos o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apartado2():\n",
    "    vocab = getVocabDict()\n",
    "    Xspam, yspam = read_directory('spam/*.txt', vocab)\n",
    "\n",
    "    Xeasy_ham, yeasy_ham = read_directory('easy_ham/*.txt', vocab)\n",
    "\n",
    "    Xhard_ham, yhard_ham = read_directory('hard_ham/*.txt', vocab)\n",
    "\n",
    "    X = np.vstack((Xspam, Xeasy_ham, Xhard_ham))\n",
    "\n",
    "    yspam = [1]*len(Xspam)\n",
    "    yeasy_ham = [0]*len(Xeasy_ham)\n",
    "    yhard_ham = [0]*len(Xhard_ham)\n",
    "    y = np.r_[yspam, yeasy_ham, yhard_ham]\n",
    "\n",
    "    # con reducción de atributos\n",
    "    X_freq = palabras_comunes(X, 0.1)\n",
    "\n",
    "    score_emails(X_freq, y)\n",
    "\n",
    "    # sin reducción de atributos\n",
    "\n",
    "    score_emails(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recolectamos los datos de los tres directorios y primero utilizamos _score_emails_ con reducción de atributos, y después sin ella. Los resultados obtenidos son los siguientes:\n",
    "\n",
    "Con reducción de atributos:\n",
    "\n",
    "Error mínimo: 0.025757575757575757  \n",
    "C óptimo: 1, $\\sigma$ óptimo: 3  \n",
    "Precisión: 97.428%  \n",
    "Tiempo de ejecución: 42.3125  \n",
    "Matriz de confusión:  \n",
    "[[550   5]  \n",
    " [ 12  94]]\n",
    "\n",
    "Sin reducción de atributos:\n",
    "\n",
    "Error mínimo: 0.015151515151515138  \n",
    "C óptimo: 10, $\\sigma$ óptimo: 10  \n",
    "Precisión: 98.185%  \n",
    "Tiempo de ejecución: 379.59375  \n",
    "Matriz de confusión:  \n",
    "[[551   4]  \n",
    " [  8  98]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
